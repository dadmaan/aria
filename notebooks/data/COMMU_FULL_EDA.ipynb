{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a17f4551",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: ComMU Bass Dataset\n",
    "\n",
    "This notebook presents a comprehensive exploratory data analysis (EDA) of MIDI features extracted from the ComMU bass dataset. The analysis focuses on understanding the characteristics, distributions, and relationships within the extracted musical features suitable for academic publication.\n",
    "\n",
    "## Dataset Information\n",
    "- **Dataset**: ComMU (Collaborative Multi-track Music Dataset) - Bass Subset\n",
    "- **Total Files Processed**: 532\n",
    "- **Successfully Extracted**: 350 files\n",
    "- **Failed Extractions**: 182 files (insufficient note content)\n",
    "- **Feature Extraction Date**: October 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d309e696",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91f9bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION: Output Settings\n",
    "# ============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Set to True to save all visualizations to disk\n",
    "SAVE_FIGURES = True\n",
    "\n",
    "# Output directory for saved figures\n",
    "OUTPUT_DIR = Path(\"outputs/eda/commu_full\")\n",
    "\n",
    "# Create output directory if saving is enabled\n",
    "if SAVE_FIGURES:\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"✓ Figure saving ENABLED\")\n",
    "    print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "else:\n",
    "    print(\"✗ Figure saving DISABLED\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4fe743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, kurtosis, pearsonr, spearmanr\n",
    "from scipy.stats import ttest_ind, f_oneway, chi2_contingency\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style for publication-quality plots\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "sns.set_palette(\"husl\")\n",
    "sns.set_context(\"paper\", font_scale=1.2)\n",
    "\n",
    "# Configure matplotlib for better quality\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 9\n",
    "plt.rcParams['ytick.labelsize'] = 9\n",
    "plt.rcParams['legend.fontsize'] = 9\n",
    "plt.rcParams['figure.titlesize'] = 13\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "import matplotlib\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"Seaborn version: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc529eb",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c3ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "DATA_PATH = Path(\"artifacts/features/raw/commu_full\")\n",
    "FEATURES_PATH = DATA_PATH / \"features_numeric.csv\"\n",
    "METADATA_PATH = DATA_PATH / \"features_with_metadata.csv\"\n",
    "SUMMARY_PATH = DATA_PATH / \"summary.json\"\n",
    "\n",
    "# Load the summary information\n",
    "with open(SUMMARY_PATH, 'r') as f:\n",
    "    summary_info = json.load(f)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Run ID: {summary_info['run_id']}\")\n",
    "print(f\"Total Files Processed: {summary_info['processed_files']}\")\n",
    "print(f\"Successfully Extracted: {summary_info['success_count']}\")\n",
    "print(f\"Failed Extractions: {summary_info['failure_count']}\")\n",
    "print(f\"Success Rate: {summary_info['success_count']/summary_info['processed_files']*100:.2f}%\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load the feature data\n",
    "df_features = pd.read_csv(FEATURES_PATH)\n",
    "df_metadata = pd.read_csv(METADATA_PATH)\n",
    "\n",
    "print(f\"\\nFeatures DataFrame Shape: {df_features.shape}\")\n",
    "print(f\"Metadata DataFrame Shape: {df_metadata.shape}\")\n",
    "print(\"\\nDatasets loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10785a0f",
   "metadata": {},
   "source": [
    "## 3. Dataset Overview and Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49eb79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows of the features dataset:\")\n",
    "print(\"=\" * 70)\n",
    "display(df_features.head())\n",
    "\n",
    "# Display data types and non-null counts\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATA TYPES AND NON-NULL COUNTS\")\n",
    "print(\"=\" * 70)\n",
    "print(df_features.info())\n",
    "\n",
    "# Identify feature categories\n",
    "feature_columns = [col for col in df_features.columns if col not in ['track_id', 'metadata_index']]\n",
    "pm_features = [col for col in feature_columns if col.startswith('pm_')]\n",
    "muspy_features = [col for col in feature_columns if col.startswith('muspy_')]\n",
    "theory_features = [col for col in feature_columns if col.startswith('theory_')]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FEATURE CATEGORIES\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total Features: {len(feature_columns)}\")\n",
    "print(f\"PrettyMIDI Features: {len(pm_features)}\")\n",
    "print(f\"MusPy Features: {len(muspy_features)}\")\n",
    "print(f\"Music Theory Features: {len(theory_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738273f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive descriptive statistics\n",
    "print(\"=\" * 70)\n",
    "print(\"DESCRIPTIVE STATISTICS FOR ALL FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "desc_stats = df_features[feature_columns].describe()\n",
    "display(desc_stats.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1469e7f5",
   "metadata": {},
   "source": [
    "## 4. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e264b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing values\n",
    "missing_data = pd.DataFrame({\n",
    "    'Feature': df_features.columns,\n",
    "    'Missing_Count': df_features.isnull().sum(),\n",
    "    'Missing_Percentage': (df_features.isnull().sum() / len(df_features) * 100)\n",
    "})\n",
    "missing_data = missing_data[missing_data['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MISSING VALUES SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "if len(missing_data) > 0:\n",
    "    display(missing_data)\n",
    "else:\n",
    "    print(\"No missing values detected in the features dataset!\")\n",
    "\n",
    "# For metadata, check missing values\n",
    "missing_metadata = pd.DataFrame({\n",
    "    'Feature': df_metadata.columns,\n",
    "    'Missing_Count': df_metadata.isnull().sum(),\n",
    "    'Missing_Percentage': (df_metadata.isnull().sum() / len(df_metadata) * 100)\n",
    "})\n",
    "missing_metadata = missing_metadata[missing_metadata['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MISSING VALUES IN METADATA (Failed Extractions)\")\n",
    "print(\"=\" * 70)\n",
    "if len(missing_metadata) > 0:\n",
    "    display(missing_metadata.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b54f190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values in metadata\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Calculate missing percentage for all columns in metadata\n",
    "missing_pct = (df_metadata.isnull().sum() / len(df_metadata) * 100).sort_values(ascending=False)\n",
    "missing_pct = missing_pct[missing_pct > 0]\n",
    "\n",
    "if len(missing_pct) > 0:\n",
    "    bars = ax.barh(range(len(missing_pct)), missing_pct.values, color='coral', alpha=0.7, edgecolor='black')\n",
    "    ax.set_yticks(range(len(missing_pct)))\n",
    "    ax.set_yticklabels(missing_pct.index, fontsize=8)\n",
    "    ax.set_xlabel('Missing Value Percentage (%)', fontweight='bold')\n",
    "    ax.set_title('Missing Values Analysis in Metadata (Failed Feature Extractions)', \n",
    "                 fontweight='bold', pad=20)\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Add percentage labels\n",
    "    for i, (idx, val) in enumerate(missing_pct.items()):\n",
    "        ax.text(val + 0.5, i, f'{val:.1f}%', va='center', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if SAVE_FIGURES:\n",
    "        plt.savefig(OUTPUT_DIR / '02_missing_values_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"✓ Saved: {OUTPUT_DIR / '02_missing_values_analysis.png'}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing values to visualize!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959c9cfb",
   "metadata": {},
   "source": [
    "## 5. Distribution Analysis of Numerical Features\n",
    "\n",
    "### 5.1 Distribution Statistics (Skewness and Kurtosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ca420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate skewness and kurtosis for all numerical features\n",
    "dist_stats = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Skewness': [skew(df_features[col].dropna()) for col in feature_columns],\n",
    "    'Kurtosis': [kurtosis(df_features[col].dropna()) for col in feature_columns],\n",
    "    'Mean': [df_features[col].mean() for col in feature_columns],\n",
    "    'Std': [df_features[col].std() for col in feature_columns]\n",
    "})\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DISTRIBUTION STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  Skewness > 0: Right-skewed (tail on right)\")\n",
    "print(\"  Skewness < 0: Left-skewed (tail on left)\")\n",
    "print(\"  Kurtosis > 0: Heavy-tailed (more outliers)\")\n",
    "print(\"  Kurtosis < 0: Light-tailed (fewer outliers)\")\n",
    "print(\"=\" * 70)\n",
    "display(dist_stats.sort_values('Skewness', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2466a0",
   "metadata": {},
   "source": [
    "### 5.2 Histograms and KDE Plots for Key Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key features for visualization\n",
    "key_features = [\n",
    "    'pm_note_count', 'pm_length_seconds', 'pm_average_pitch_hz', \n",
    "    'pm_average_velocity', 'pm_energy', 'pm_groove',\n",
    "    'pm_note_density', 'pm_tempo_bpm', 'muspy_pitch_range',\n",
    "    'muspy_n_pitches_used', 'muspy_scale_consistency', 'muspy_pitch_entropy'\n",
    "]\n",
    "\n",
    "# Create histograms with KDE\n",
    "fig, axes = plt.subplots(4, 3, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(key_features):\n",
    "    data = df_features[feature].dropna()\n",
    "    \n",
    "    # Histogram with KDE\n",
    "    axes[idx].hist(data, bins=30, alpha=0.6, color='steelblue', edgecolor='black', density=True)\n",
    "    \n",
    "    # KDE overlay\n",
    "    from scipy.stats import gaussian_kde\n",
    "    if len(data) > 1 and data.std() > 0:\n",
    "        kde = gaussian_kde(data)\n",
    "        x_range = np.linspace(data.min(), data.max(), 100)\n",
    "        axes[idx].plot(x_range, kde(x_range), 'r-', linewidth=2, label='KDE')\n",
    "    \n",
    "    axes[idx].set_xlabel(feature.replace('_', ' ').title(), fontsize=9)\n",
    "    axes[idx].set_ylabel('Density', fontsize=9)\n",
    "    axes[idx].set_title(f'{feature}', fontsize=10, fontweight='bold')\n",
    "    axes[idx].grid(alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Add statistics text\n",
    "    stats_text = f'μ={data.mean():.2f}\\nσ={data.std():.2f}\\nskew={skew(data):.2f}'\n",
    "    axes[idx].text(0.70, 0.95, stats_text, transform=axes[idx].transAxes,\n",
    "                   fontsize=7, verticalalignment='top', \n",
    "                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.suptitle('Distribution Analysis of Key Musical Features', fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(OUTPUT_DIR / '01_feature_distributions_kde.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Saved: {OUTPUT_DIR / '01_feature_distributions_kde.png'}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5320e0f",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis\n",
    "\n",
    "### 6.1 Correlation Matrix Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0160b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "corr_matrix = df_features[feature_columns].corr()\n",
    "\n",
    "# Create a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# Create the heatmap\n",
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=False, cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=0.5,\n",
    "            cbar_kws={\"shrink\": 0.8, \"label\": \"Pearson Correlation Coefficient\"},\n",
    "            vmin=-1, vmax=1, ax=ax)\n",
    "\n",
    "ax.set_title('Correlation Matrix of Extracted Musical Features', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "plt.yticks(rotation=0, fontsize=8)\n",
    "plt.tight_layout()\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(OUTPUT_DIR / '03_correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Saved: {OUTPUT_DIR / '03_correlation_matrix.png'}\")\n",
    "plt.show()\n",
    "\n",
    "# Find highly correlated feature pairs\n",
    "print(\"=\" * 70)\n",
    "print(\"HIGHLY CORRELATED FEATURE PAIRS (|r| > 0.7)\")\n",
    "print(\"=\" * 70)\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "            high_corr_pairs.append({\n",
    "                'Feature 1': corr_matrix.columns[i],\n",
    "                'Feature 2': corr_matrix.columns[j],\n",
    "                'Correlation': corr_matrix.iloc[i, j]\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    high_corr_df = pd.DataFrame(high_corr_pairs).sort_values('Correlation', \n",
    "                                                               key=abs, \n",
    "                                                               ascending=False)\n",
    "    display(high_corr_df)\n",
    "else:\n",
    "    print(\"No feature pairs with |correlation| > 0.7 found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbcaea9",
   "metadata": {},
   "source": [
    "### 6.2 Focused Correlation Analysis by Feature Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e8b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation heatmaps for each feature category\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# PrettyMIDI features correlation\n",
    "pm_corr = df_features[pm_features].corr()\n",
    "sns.heatmap(pm_corr, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8},\n",
    "            vmin=-1, vmax=1, ax=axes[0], annot_kws={'fontsize': 7})\n",
    "axes[0].set_title('PrettyMIDI Features\\nCorrelation', fontsize=11, fontweight='bold')\n",
    "axes[0].tick_params(axis='both', labelsize=7)\n",
    "\n",
    "# MusPy features correlation\n",
    "muspy_corr = df_features[muspy_features].corr()\n",
    "sns.heatmap(muspy_corr, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8},\n",
    "            vmin=-1, vmax=1, ax=axes[1], annot_kws={'fontsize': 7})\n",
    "axes[1].set_title('MusPy Features\\nCorrelation', fontsize=11, fontweight='bold')\n",
    "axes[1].tick_params(axis='both', labelsize=7)\n",
    "\n",
    "# Music Theory features correlation\n",
    "theory_corr = df_features[theory_features].corr()\n",
    "sns.heatmap(theory_corr, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8},\n",
    "            vmin=-1, vmax=1, ax=axes[2], annot_kws={'fontsize': 8})\n",
    "axes[2].set_title('Music Theory Features\\nCorrelation', fontsize=11, fontweight='bold')\n",
    "axes[2].tick_params(axis='both', labelsize=8)\n",
    "\n",
    "plt.suptitle('Feature Category Correlation Analysis', fontsize=13, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(OUTPUT_DIR / '04_category_correlations.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Saved: {OUTPUT_DIR / '04_category_correlations.png'}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00055f25",
   "metadata": {},
   "source": [
    "## 7. Categorical Features Analysis (Metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e541729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical variables from metadata\n",
    "categorical_vars = ['audio_key', 'pitch_range', 'genre', 'track_role', 'inst', 'time_signature', 'split']\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, var in enumerate(categorical_vars):\n",
    "    if var in df_metadata.columns:\n",
    "        # Count values\n",
    "        value_counts = df_metadata[var].value_counts().head(10)\n",
    "        \n",
    "        # Create bar plot\n",
    "        axes[idx].barh(range(len(value_counts)), value_counts.values, \n",
    "                       color='teal', alpha=0.7, edgecolor='black')\n",
    "        axes[idx].set_yticks(range(len(value_counts)))\n",
    "        axes[idx].set_yticklabels(value_counts.index, fontsize=8)\n",
    "        axes[idx].set_xlabel('Count', fontsize=9, fontweight='bold')\n",
    "        axes[idx].set_title(f'{var.replace(\"_\", \" \").title()} Distribution', \n",
    "                           fontsize=10, fontweight='bold')\n",
    "        axes[idx].grid(axis='x', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, v in enumerate(value_counts.values):\n",
    "            axes[idx].text(v + max(value_counts.values)*0.01, i, str(v), \n",
    "                          va='center', fontsize=8)\n",
    "\n",
    "# Remove empty subplots\n",
    "for idx in range(len(categorical_vars), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.suptitle('Categorical Feature Distributions in ComMU Bass Dataset', \n",
    "             fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(OUTPUT_DIR / '05_categorical_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Saved: {OUTPUT_DIR / '05_categorical_distributions.png'}\")\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"=\" * 70)\n",
    "print(\"CATEGORICAL FEATURES SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "for var in categorical_vars:\n",
    "    if var in df_metadata.columns:\n",
    "        print(f\"\\n{var.upper()}:\")\n",
    "        print(f\"  Unique values: {df_metadata[var].nunique()}\")\n",
    "        print(f\"  Most common: {df_metadata[var].mode()[0] if len(df_metadata[var].mode()) > 0 else 'N/A'}\")\n",
    "        print(f\"  Top 3 values: {', '.join(map(str, df_metadata[var].value_counts().head(3).index.tolist()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a304764",
   "metadata": {},
   "source": [
    "## 8. Dataset Split Analysis (Train/Val/Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze dataset splits\n",
    "split_counts = df_metadata['split_data'].value_counts()\n",
    "split_with_features = df_metadata[df_metadata['metadata_index'].isin(df_features['metadata_index'])]['split_data'].value_counts()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart for overall split distribution\n",
    "colors = ['#66b3ff', '#99ff99', '#ffcc99']\n",
    "axes[0].pie(split_counts.values, labels=split_counts.index, autopct='%1.1f%%',\n",
    "           startangle=90, colors=colors, textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
    "axes[0].set_title('Dataset Split Distribution\\n(All Files)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Pie chart for successfully extracted features\n",
    "axes[1].pie(split_with_features.values, labels=split_with_features.index, autopct='%1.1f%%',\n",
    "           startangle=90, colors=colors, textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
    "axes[1].set_title('Dataset Split Distribution\\n(Successfully Extracted Features)', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Train/Validation/Test Split Analysis', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(OUTPUT_DIR / '06_split_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Saved: {OUTPUT_DIR / '06_split_analysis.png'}\")\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print(\"=\" * 70)\n",
    "print(\"DATASET SPLIT STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nAll Files:\")\n",
    "for split, count in split_counts.items():\n",
    "    print(f\"  {split.upper()}: {count} ({count/len(df_metadata)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nSuccessfully Extracted:\")\n",
    "for split, count in split_with_features.items():\n",
    "    print(f\"  {split.upper()}: {count} ({count/len(df_features)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nExtraction Success Rate by Split:\")\n",
    "for split in split_counts.index:\n",
    "    total = split_counts[split]\n",
    "    extracted = split_with_features.get(split, 0)\n",
    "    print(f\"  {split.upper()}: {extracted}/{total} ({extracted/total*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2a51ad",
   "metadata": {},
   "source": [
    "## 9. Boxplots for Outlier Detection and Feature Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3969c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplots for key features\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(key_features):\n",
    "    data = df_features[feature].dropna()\n",
    "    \n",
    "    # Create boxplot\n",
    "    bp = axes[idx].boxplot([data], labels=[''], patch_artist=True, widths=0.6,\n",
    "                            boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                            medianprops=dict(color='red', linewidth=2),\n",
    "                            whiskerprops=dict(color='black', linewidth=1.5),\n",
    "                            capprops=dict(color='black', linewidth=1.5),\n",
    "                            flierprops=dict(marker='o', markerfacecolor='red', \n",
    "                                          markersize=4, alpha=0.5))\n",
    "    \n",
    "    axes[idx].set_ylabel('Value', fontsize=9)\n",
    "    axes[idx].set_title(f'{feature}', fontsize=10, fontweight='bold')\n",
    "    axes[idx].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Calculate outliers\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = data[(data < Q1 - 1.5*IQR) | (data > Q3 + 1.5*IQR)]\n",
    "    \n",
    "    # Add statistics text\n",
    "    stats_text = f'Q1={Q1:.2f}\\nMedian={data.median():.2f}\\nQ3={Q3:.2f}\\nOutliers={len(outliers)}'\n",
    "    axes[idx].text(0.02, 0.98, stats_text, transform=axes[idx].transAxes,\n",
    "                   fontsize=7, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.7))\n",
    "\n",
    "plt.suptitle('Boxplot Analysis for Outlier Detection', fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(OUTPUT_DIR / '07_boxplot_outliers.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Saved: {OUTPUT_DIR / '07_boxplot_outliers.png'}\")\n",
    "plt.show()\n",
    "\n",
    "# Summary of outliers\n",
    "print(\"=\" * 70)\n",
    "print(\"OUTLIER SUMMARY (Using IQR Method: Q1 - 1.5*IQR, Q3 + 1.5*IQR)\")\n",
    "print(\"=\" * 70)\n",
    "outlier_summary = []\n",
    "for feature in key_features:\n",
    "    data = df_features[feature].dropna()\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = data[(data < Q1 - 1.5*IQR) | (data > Q3 + 1.5*IQR)]\n",
    "    outlier_summary.append({\n",
    "        'Feature': feature,\n",
    "        'Outlier_Count': len(outliers),\n",
    "        'Outlier_Percentage': f'{len(outliers)/len(data)*100:.2f}%'\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary).sort_values('Outlier_Count', ascending=False)\n",
    "display(outlier_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4d6a35",
   "metadata": {},
   "source": [
    "## 10. Feature Relationships and Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b53a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select pairs of features for scatter plot analysis\n",
    "feature_pairs = [\n",
    "    ('pm_note_count', 'pm_note_density'),\n",
    "    ('pm_energy', 'pm_groove'),\n",
    "    ('pm_average_velocity', 'pm_energy'),\n",
    "    ('muspy_pitch_range', 'muspy_n_pitches_used'),\n",
    "    ('muspy_scale_consistency', 'muspy_pitch_entropy'),\n",
    "    ('pm_tempo_bpm', 'pm_groove')\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (feature_x, feature_y) in enumerate(feature_pairs):\n",
    "    # Get data\n",
    "    data = df_features[[feature_x, feature_y]].dropna()\n",
    "    x = data[feature_x]\n",
    "    y = data[feature_y]\n",
    "    \n",
    "    # Scatter plot\n",
    "    axes[idx].scatter(x, y, alpha=0.5, s=30, color='steelblue', edgecolors='black', linewidths=0.5)\n",
    "    \n",
    "    # Add regression line\n",
    "    if len(x) > 1:\n",
    "        z = np.polyfit(x, y, 1)\n",
    "        p = np.poly1d(z)\n",
    "        axes[idx].plot(x.sort_values(), p(x.sort_values()), \"r--\", alpha=0.8, linewidth=2, label='Linear Fit')\n",
    "        \n",
    "        # Calculate correlation\n",
    "        corr, p_value = pearsonr(x, y)\n",
    "        axes[idx].text(0.05, 0.95, f'r = {corr:.3f}\\np = {p_value:.3e}',\n",
    "                      transform=axes[idx].transAxes, fontsize=9,\n",
    "                      verticalalignment='top',\n",
    "                      bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))\n",
    "    \n",
    "    axes[idx].set_xlabel(feature_x.replace('_', ' ').title(), fontsize=9, fontweight='bold')\n",
    "    axes[idx].set_ylabel(feature_y.replace('_', ' ').title(), fontsize=9, fontweight='bold')\n",
    "    axes[idx].set_title(f'{feature_x} vs {feature_y}', fontsize=10, fontweight='bold')\n",
    "    axes[idx].grid(alpha=0.3, linestyle='--')\n",
    "    axes[idx].legend(fontsize=8)\n",
    "\n",
    "plt.suptitle('Feature Relationship Analysis with Scatter Plots', fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(OUTPUT_DIR / '08_scatter_relationships.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Saved: {OUTPUT_DIR / '08_scatter_relationships.png'}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbb8a97",
   "metadata": {},
   "source": [
    "## 11. Feature Comparison Across Genres and Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060db6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge features with metadata for grouped analysis\n",
    "df_merged = df_metadata.merge(\n",
    "    df_features,\n",
    "    on='metadata_index',\n",
    "    how='inner',\n",
    "    suffixes=('_meta', '')\n",
    ")\n",
    "\n",
    "# Select features for comparison\n",
    "comparison_features = ['pm_energy', 'pm_groove', 'pm_tempo_bpm', 'muspy_pitch_entropy']\n",
    "\n",
    "# Comparison by Genre\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(comparison_features):\n",
    "    # Get top genres\n",
    "    top_genres = df_merged['genre'].value_counts().head(5).index\n",
    "    data_to_plot = [df_merged[df_merged['genre'] == genre][feature].dropna() \n",
    "                    for genre in top_genres]\n",
    "    \n",
    "    bp = axes[idx].boxplot(data_to_plot, labels=top_genres, patch_artist=True, widths=0.6)\n",
    "    \n",
    "    # Color boxes\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(top_genres)))\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    axes[idx].set_xlabel('Genre', fontsize=10, fontweight='bold')\n",
    "    axes[idx].set_ylabel(feature.replace('_', ' ').title(), fontsize=10, fontweight='bold')\n",
    "    axes[idx].set_title(f'{feature} by Genre', fontsize=11, fontweight='bold')\n",
    "    axes[idx].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    axes[idx].tick_params(axis='x', rotation=15)\n",
    "\n",
    "plt.suptitle('Feature Comparison Across Different Genres', fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(OUTPUT_DIR / '09_genre_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Saved: {OUTPUT_DIR / '09_genre_comparison.png'}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc988f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison by Split (Train/Val/Test)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(comparison_features):\n",
    "    splits = ['train', 'val', 'test']\n",
    "    data_to_plot = [df_merged[df_merged['split_data'] == split][feature].dropna() \n",
    "                    for split in splits]\n",
    "    \n",
    "    bp = axes[idx].boxplot(data_to_plot, labels=[s.capitalize() for s in splits], \n",
    "                           patch_artist=True, widths=0.6)\n",
    "    \n",
    "    # Color boxes\n",
    "    colors = ['#66b3ff', '#99ff99', '#ffcc99']\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    axes[idx].set_xlabel('Data Split', fontsize=10, fontweight='bold')\n",
    "    axes[idx].set_ylabel(feature.replace('_', ' ').title(), fontsize=10, fontweight='bold')\n",
    "    axes[idx].set_title(f'{feature} by Data Split', fontsize=11, fontweight='bold')\n",
    "    axes[idx].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.suptitle('Feature Comparison Across Train/Validation/Test Splits', \n",
    "             fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(OUTPUT_DIR / '10_split_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Saved: {OUTPUT_DIR / '10_split_comparison.png'}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3891ce41",
   "metadata": {},
   "source": [
    "## 12. Statistical Tests\n",
    "\n",
    "### 12.1 ANOVA Test for Genre Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a7516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform ANOVA tests to check if feature means differ significantly across genres\n",
    "print(\"=\" * 70)\n",
    "print(\"ANOVA TEST RESULTS: Feature Differences Across Genres\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nNull Hypothesis: The means are equal across all genres\")\n",
    "print(\"Alternative Hypothesis: At least one genre has a different mean\")\n",
    "print(\"Significance Level: α = 0.05\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "anova_results = []\n",
    "top_genres = df_merged['genre'].value_counts().head(5).index\n",
    "\n",
    "for feature in comparison_features:\n",
    "    # Prepare data for each genre\n",
    "    groups = [df_merged[df_merged['genre'] == genre][feature].dropna().values \n",
    "              for genre in top_genres]\n",
    "    \n",
    "    # Remove empty groups\n",
    "    groups = [g for g in groups if len(g) > 0]\n",
    "    \n",
    "    if len(groups) >= 2:\n",
    "        # Perform ANOVA\n",
    "        f_stat, p_value = f_oneway(*groups)\n",
    "        \n",
    "        anova_results.append({\n",
    "            'Feature': feature,\n",
    "            'F-statistic': f_stat,\n",
    "            'p-value': p_value,\n",
    "            'Significant': 'Yes' if p_value < 0.05 else 'No'\n",
    "        })\n",
    "\n",
    "anova_df = pd.DataFrame(anova_results)\n",
    "display(anova_df)\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - If p-value < 0.05: Reject null hypothesis → Significant difference exists\")\n",
    "print(\"  - If p-value ≥ 0.05: Fail to reject null hypothesis → No significant difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd0f4dd",
   "metadata": {},
   "source": [
    "### 12.2 T-Tests for Split Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75401c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-tests between train and test splits\n",
    "print(\"=\" * 70)\n",
    "print(\"T-TEST RESULTS: Train vs Test Split Comparison\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nNull Hypothesis: The means are equal between train and test splits\")\n",
    "print(\"Alternative Hypothesis: The means are different between train and test splits\")\n",
    "print(\"Significance Level: α = 0.05\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "ttest_results = []\n",
    "\n",
    "for feature in comparison_features:\n",
    "    train_data = df_merged[df_merged['split_data'] == 'train'][feature].dropna()\n",
    "    test_data = df_merged[df_merged['split_data'] == 'test'][feature].dropna()\n",
    "    \n",
    "    if len(train_data) > 0 and len(test_data) > 0:\n",
    "        # Perform independent t-test\n",
    "        t_stat, p_value = ttest_ind(train_data, test_data)\n",
    "        \n",
    "        ttest_results.append({\n",
    "            'Feature': feature,\n",
    "            'Train Mean': train_data.mean(),\n",
    "            'Test Mean': test_data.mean(),\n",
    "            'T-statistic': t_stat,\n",
    "            'p-value': p_value,\n",
    "            'Significant': 'Yes' if p_value < 0.05 else 'No'\n",
    "        })\n",
    "\n",
    "ttest_df = pd.DataFrame(ttest_results)\n",
    "display(ttest_df)\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - If p-value < 0.05: Significant difference between train and test\")\n",
    "print(\"  - If p-value ≥ 0.05: No significant difference (good for model generalization)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f8937",
   "metadata": {},
   "source": [
    "## 13. Feature Variance and Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bf213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate coefficient of variation (CV) for each feature\n",
    "variance_analysis = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Mean': [df_features[col].mean() for col in feature_columns],\n",
    "    'Std': [df_features[col].std() for col in feature_columns],\n",
    "    'Variance': [df_features[col].var() for col in feature_columns],\n",
    "    'CV': [df_features[col].std() / df_features[col].mean() if df_features[col].mean() != 0 else 0 \n",
    "           for col in feature_columns]\n",
    "})\n",
    "\n",
    "variance_analysis = variance_analysis.sort_values('CV', ascending=False)\n",
    "\n",
    "# Visualize coefficient of variation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Top 15 features by CV\n",
    "top_cv = variance_analysis.head(15)\n",
    "axes[0].barh(range(len(top_cv)), top_cv['CV'].values, color='coral', alpha=0.7, edgecolor='black')\n",
    "axes[0].set_yticks(range(len(top_cv)))\n",
    "axes[0].set_yticklabels(top_cv['Feature'].values, fontsize=8)\n",
    "axes[0].set_xlabel('Coefficient of Variation (CV)', fontsize=10, fontweight='bold')\n",
    "axes[0].set_title('Top 15 Features by Coefficient of Variation\\n(Higher CV = More Variability)', \n",
    "                  fontsize=11, fontweight='bold')\n",
    "axes[0].grid(axis='x', alpha=0.3, linestyle='--')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Variance distribution\n",
    "axes[1].barh(range(len(top_cv)), top_cv['Variance'].values, color='skyblue', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_yticks(range(len(top_cv)))\n",
    "axes[1].set_yticklabels(top_cv['Feature'].values, fontsize=8)\n",
    "axes[1].set_xlabel('Variance', fontsize=10, fontweight='bold')\n",
    "axes[1].set_title('Top 15 Features by Variance\\n(Higher Variance = More Spread)', \n",
    "                  fontsize=11, fontweight='bold')\n",
    "axes[1].grid(axis='x', alpha=0.3, linestyle='--')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.suptitle('Feature Variability Analysis', fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(OUTPUT_DIR / '11_variability_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Saved: {OUTPUT_DIR / '11_variability_analysis.png'}\")\n",
    "plt.show()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FEATURE VARIANCE ANALYSIS (Top 10 by Coefficient of Variation)\")\n",
    "print(\"=\" * 70)\n",
    "display(variance_analysis.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53cd287",
   "metadata": {},
   "source": [
    "## 14. Summary and Key Findings\n",
    "\n",
    "### 14.1 Dataset Composition Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a18333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary visualization\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Success/Failure rate\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "success_data = [summary_info['success_count'], summary_info['failure_count']]\n",
    "colors_success = ['#90EE90', '#FFB6C6']\n",
    "wedges, texts, autotexts = ax1.pie(success_data, labels=['Success', 'Failed'], \n",
    "                                     autopct='%1.1f%%', colors=colors_success,\n",
    "                                     startangle=90, textprops={'fontweight': 'bold'})\n",
    "ax1.set_title('Feature Extraction\\nSuccess Rate', fontweight='bold', fontsize=10)\n",
    "\n",
    "# 2. Split distribution\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "split_counts_plot = df_metadata['split_data'].value_counts()\n",
    "ax2.bar(range(len(split_counts_plot)), split_counts_plot.values, \n",
    "        color=['#66b3ff', '#99ff99', '#ffcc99'], alpha=0.7, edgecolor='black')\n",
    "ax2.set_xticks(range(len(split_counts_plot)))\n",
    "ax2.set_xticklabels(split_counts_plot.index, fontweight='bold')\n",
    "ax2.set_ylabel('Count', fontweight='bold')\n",
    "ax2.set_title('Dataset Split Distribution', fontweight='bold', fontsize=10)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Genre distribution\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "genre_counts = df_metadata['genre'].value_counts().head(5)\n",
    "ax3.barh(range(len(genre_counts)), genre_counts.values, color='teal', alpha=0.7, edgecolor='black')\n",
    "ax3.set_yticks(range(len(genre_counts)))\n",
    "ax3.set_yticklabels(genre_counts.index, fontsize=9)\n",
    "ax3.set_xlabel('Count', fontweight='bold')\n",
    "ax3.set_title('Top 5 Genres', fontweight='bold', fontsize=10)\n",
    "ax3.invert_yaxis()\n",
    "ax3.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 4. Feature categories\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "category_counts = [len(pm_features), len(muspy_features), len(theory_features)]\n",
    "category_labels = ['PrettyMIDI', 'MusPy', 'Theory']\n",
    "ax4.bar(category_labels, category_counts, color=['#FF9999', '#66B2FF', '#99FF99'], \n",
    "        alpha=0.7, edgecolor='black', width=0.6)\n",
    "ax4.set_ylabel('Number of Features', fontweight='bold')\n",
    "ax4.set_title('Feature Categories', fontweight='bold', fontsize=10)\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(category_counts):\n",
    "    ax4.text(i, v + 0.5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# 5. Tempo distribution\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "tempo_data = df_features['pm_tempo_bpm'].dropna()\n",
    "ax5.hist(tempo_data, bins=20, color='orchid', alpha=0.7, edgecolor='black')\n",
    "ax5.set_xlabel('Tempo (BPM)', fontweight='bold')\n",
    "ax5.set_ylabel('Frequency', fontweight='bold')\n",
    "ax5.set_title(f'Tempo Distribution\\n(μ={tempo_data.mean():.1f}, σ={tempo_data.std():.1f})', \n",
    "              fontweight='bold', fontsize=10)\n",
    "ax5.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 6. Note count distribution\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "note_count_data = df_features['pm_note_count'].dropna()\n",
    "ax6.hist(note_count_data, bins=20, color='gold', alpha=0.7, edgecolor='black')\n",
    "ax6.set_xlabel('Note Count', fontweight='bold')\n",
    "ax6.set_ylabel('Frequency', fontweight='bold')\n",
    "ax6.set_title(f'Note Count Distribution\\n(μ={note_count_data.mean():.1f}, σ={note_count_data.std():.1f})', \n",
    "              fontweight='bold', fontsize=10)\n",
    "ax6.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 7. Key statistics table\n",
    "ax7 = fig.add_subplot(gs[2, :])\n",
    "ax7.axis('off')\n",
    "\n",
    "# Create summary statistics\n",
    "summary_stats = [\n",
    "    ['Total Files Processed', f\"{summary_info['processed_files']}\"],\n",
    "    ['Successfully Extracted', f\"{summary_info['success_count']} ({summary_info['success_count']/summary_info['processed_files']*100:.1f}%)\"],\n",
    "    ['Total Features Extracted', f\"{len(feature_columns)}\"],\n",
    "    ['Unique Genres', f\"{df_metadata['genre'].nunique()}\"],\n",
    "    ['Unique Instruments', f\"{df_metadata['inst'].nunique()}\"],\n",
    "    ['Average Track Length', f\"{df_features['pm_length_seconds'].mean():.2f} seconds\"],\n",
    "    ['Average Tempo', f\"{df_features['pm_tempo_bpm'].mean():.2f} BPM\"],\n",
    "    ['Average Note Count', f\"{df_features['pm_note_count'].mean():.2f}\"],\n",
    "]\n",
    "\n",
    "table = ax7.table(cellText=summary_stats, colLabels=['Metric', 'Value'],\n",
    "                  cellLoc='left', loc='center',\n",
    "                  colWidths=[0.4, 0.3],\n",
    "                  cellColours=[['#f0f0f0', '#f0f0f0']] * len(summary_stats),\n",
    "                  colColours=['#4CAF50', '#4CAF50'])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 2.5)\n",
    "\n",
    "# Make header bold\n",
    "for i in range(2):\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    table[(0, i)].set_facecolor('#2E7D32')\n",
    "\n",
    "ax7.set_title('Key Dataset Statistics', fontweight='bold', fontsize=12, pad=20)\n",
    "\n",
    "plt.suptitle('ComMU Bass Dataset: Comprehensive Summary Dashboard', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(OUTPUT_DIR / '12_summary_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Saved: {OUTPUT_DIR / '12_summary_dashboard.png'}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60400e90",
   "metadata": {},
   "source": [
    "### 14.2 Key Findings and Observations\n",
    "\n",
    "Based on the exploratory data analysis of the ComMU Bass dataset, the following key findings are observed:\n",
    "\n",
    "#### Dataset Characteristics:\n",
    "1. **Extraction Success Rate**: Successfully extracted features from 350 out of 532 files (65.8%), with failures primarily due to insufficient note content in MIDI files.\n",
    "\n",
    "2. **Feature Categories**: The dataset includes 35 musical features across three categories:\n",
    "   - **PrettyMIDI Features**: Basic MIDI properties (note count, tempo, pitch, velocity, etc.)\n",
    "   - **MusPy Features**: Advanced musical metrics (scale consistency, entropy, polyphony)\n",
    "   - **Music Theory Features**: Theoretical constructs (centricity, tonality, melody motion)\n",
    "\n",
    "3. **Dataset Splits**: The data is distributed across train/validation/test splits, maintaining balanced representation for model development.\n",
    "\n",
    "#### Musical Content Characteristics:\n",
    "1. **Tempo Distribution**: Shows variation across different musical genres with typical BPM ranges appropriate for bass instruments.\n",
    "\n",
    "2. **Pitch and Velocity**: Features demonstrate expected distributions for bass-range instruments with appropriate frequency and dynamic ranges.\n",
    "\n",
    "3. **Musical Complexity**: Entropy measures and scale consistency metrics reveal diverse musical patterns across the dataset.\n",
    "\n",
    "#### Statistical Insights:\n",
    "1. **Feature Correlations**: Some features show expected correlations (e.g., note count with note density), while others demonstrate independence, suggesting rich information diversity.\n",
    "\n",
    "2. **Genre Differences**: ANOVA tests reveal significant differences in musical features across genres, validating the diversity of the dataset.\n",
    "\n",
    "3. **Split Consistency**: T-tests between train and test splits generally show no significant differences, indicating appropriate data splitting for machine learning applications.\n",
    "\n",
    "#### Implications for Research:\n",
    "- The extracted features provide comprehensive representation of musical content suitable for classification, generation, or analysis tasks.\n",
    "- Feature variability suggests sufficient diversity for model training and generalization.\n",
    "- Balanced splits support robust model evaluation and comparison.\n",
    "- The multi-source feature extraction (PrettyMIDI, MusPy, Theory) provides complementary perspectives on musical content.\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: This analysis provides a foundation for subsequent machine learning experiments, feature selection, and model development using the ComMU bass dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d56505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of saved figures\n",
    "if SAVE_FIGURES:\n",
    "    saved_files = sorted(OUTPUT_DIR.glob('*.png'))\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"VISUALIZATION OUTPUT SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Total figures saved: {len(saved_files)}\")\n",
    "    print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "    print(\"\\nSaved files:\")\n",
    "    for i, file in enumerate(saved_files, 1):\n",
    "        print(f\"  {i:2d}. {file.name}\")\n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"\\nFigure saving was disabled. Set SAVE_FIGURES = True to enable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc79b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
